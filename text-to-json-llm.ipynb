{"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"colab":{"provenance":[],"gpuType":"T4"},"accelerator":"GPU","widgets":{"application/vnd.jupyter.widget-state+json":{"fdac2507feaa43b78c272d83cf3a8c20":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_e6cf089b1985454683930d46738b0a67","IPY_MODEL_4d71c000b0a346bc8458f82d1934725e","IPY_MODEL_1fb06ceac89a4c2e92f33d1796fc4cb0"],"layout":"IPY_MODEL_75e06e3c3afa4048bfb04d55d93b1e13"}},"e6cf089b1985454683930d46738b0a67":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_2961e3d998c94f5b9672dd940893a562","placeholder":"​","style":"IPY_MODEL_b1a41085f857472fbf37dc637d5f44a1","value":"Loading checkpoint shards: 100%"}},"4d71c000b0a346bc8458f82d1934725e":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_0cae0683f024440aac2be6bf1cdb7b99","max":2,"min":0,"orientation":"horizontal","style":"IPY_MODEL_643e86644bd543bebb8d87320631aa5a","value":2}},"1fb06ceac89a4c2e92f33d1796fc4cb0":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_bb5eed9713584efb8fbcc817c2597843","placeholder":"​","style":"IPY_MODEL_e237f93601a34485a189631d0c743e67","value":" 2/2 [00:21&lt;00:00, 21.37s/it]"}},"75e06e3c3afa4048bfb04d55d93b1e13":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"2961e3d998c94f5b9672dd940893a562":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b1a41085f857472fbf37dc637d5f44a1":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"0cae0683f024440aac2be6bf1cdb7b99":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"643e86644bd543bebb8d87320631aa5a":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"bb5eed9713584efb8fbcc817c2597843":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e237f93601a34485a189631d0c743e67":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":12525963,"sourceType":"datasetVersion","datasetId":7906984},{"sourceId":12526302,"sourceType":"datasetVersion","datasetId":7907229}],"dockerImageVersionId":31089,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"source":"<a href=\"https://www.kaggle.com/code/ub2002/text-to-json-llm?scriptVersionId=251545492\" target=\"_blank\"><img align=\"left\" alt=\"Kaggle\" title=\"Open in Kaggle\" src=\"https://kaggle.com/static/images/open-in-kaggle.svg\"></a>","metadata":{},"cell_type":"markdown"},{"cell_type":"code","source":"from transformers import AutoTokenizer, AutoModelForCausalLM\nimport torch\nimport json","metadata":{"id":"4RqeEZD9A_po","trusted":true,"execution":{"iopub.status.busy":"2025-07-20T17:53:11.766372Z","iopub.execute_input":"2025-07-20T17:53:11.76669Z","iopub.status.idle":"2025-07-20T17:53:23.610853Z","shell.execute_reply.started":"2025-07-20T17:53:11.766664Z","shell.execute_reply":"2025-07-20T17:53:23.610091Z"}},"outputs":[],"execution_count":1},{"cell_type":"code","source":"from kaggle_secrets import UserSecretsClient\nuser_secrets = UserSecretsClient()\nkey = user_secrets.get_secret(\"Token\")","metadata":{"id":"xXWfQXG3BCQE","trusted":true,"execution":{"iopub.status.busy":"2025-07-20T17:53:23.612234Z","iopub.execute_input":"2025-07-20T17:53:23.612616Z","iopub.status.idle":"2025-07-20T17:53:23.776729Z","shell.execute_reply.started":"2025-07-20T17:53:23.612595Z","shell.execute_reply":"2025-07-20T17:53:23.776222Z"}},"outputs":[],"execution_count":2},{"cell_type":"code","source":"MODEL_ID=\"google/gemma-2-9b-it\"\ninput_text = \"\"\"# \"MkDocs Publisher\" Action\n\nI keep repeating the steps to build and deploy our MkDocs documentation sites to GitHub Pages across different repos. Let's create a reusable composite action to handle this.\n\nAction Name: MkDocs Publisher\nPurpose: A simple action to build an MkDocs site and push it to the gh-pages branch. Should be easy to use. Author should be listed as 'DevRel Team'.\n\nInputs Needed:\n\npython-version: We need to specify the Python version for setting up the environment. Users should be able to choose. Let's make this optional and default it to 3.11. Description: 'The version of Python to set up for building.'\nrequirements-file: Users might have different requirements files (e.g., requirements.txt, docs/requirements.txt). This input should specify the path. It's required. Description: 'Path to the Python requirements file'.\ngh-token: The GitHub token for pushing to gh-pages. This is absolutely required. Description: 'GitHub token for deployment.' Let's add a note that this is usually ${{ secrets.GITHUB_TOKEN }}. We should probably add a deprecation message to this input later if we find a better way, maybe: \"Prefer using GITHUB_TOKEN environment variable directly if permissions allow.\"\nOutputs:\n\nThe action needs to output the URL where the site was deployed. Let's call this output page-url. Its description should be 'The URL of the deployed GitHub Pages site.' The actual value should come from the deployment step (see below).\n\nHow it Runs (Execution):\n\nThis will be a composite action (using: composite). Here are the steps involved:\n\nCheckout Code: First, we need the repository code. Use the standard actions/checkout@v4.\nSetup Python: Next, set up the Python environment. Use actions/setup-python@v5. We must use the python-version input provided by the user here. Let's ID this step as setup_python.\nInstall Dependencies: Run a command to install the Python packages. The command is pip install -r ${{ inputs.requirements-file }}. Execute this using the bash shell. Maybe give this step the name \"Install Python Packages\".\nBuild Site: Run the command mkdocs build. Use bash for this too.\nDeploy to Pages: Use an existing action for the deployment. peaceiris/actions-gh-pages@v3 seems popular. Give this step the ID deploy. We need to configure it:\nSet its github_token parameter to the gh-token input we defined earlier.\nSet its publish_dir parameter to ./site (which is the default build output dir for MkDocs).\nMaybe add a condition (if:): github.ref == 'refs/heads/main' so it only deploys from the main branch.\n\nRemember the page-url output? Its value needs to be linked to the output of the deploy step. So, for the page-url output, the value should be ${{ steps.deploy.outputs.page_url }}.\n\nBranding:\nFor the marketplace look, let's use the color blue and the book-open icon. Looks professional.\n\"\"\"\nwith open(\"/kaggle/input/schema/schema.json\", \"r\") as f:\n  json_schema = json.load(f)\n\n\njson_schema_str = json.dumps(json_schema, indent=2)\n\n\nprompt = f'''Below is a text paired with input that provides further context. Write JSON output only json code as output.\n### Input:\n{input_text}\n### Schema:\n{json_schema_str}\n### Response:\n'''","metadata":{"id":"pONky0l1Eq1G","trusted":true,"execution":{"iopub.status.busy":"2025-07-20T17:53:23.777326Z","iopub.execute_input":"2025-07-20T17:53:23.777495Z","iopub.status.idle":"2025-07-20T17:53:23.789227Z","shell.execute_reply.started":"2025-07-20T17:53:23.777482Z","shell.execute_reply":"2025-07-20T17:53:23.788571Z"}},"outputs":[],"execution_count":3},{"cell_type":"code","source":"tokenizer = AutoTokenizer.from_pretrained(MODEL_ID, token=key)\nmodel = AutoModelForCausalLM.from_pretrained(\n    MODEL_ID,\n    token=key,\n    torch_dtype=torch.float16 if torch.cuda.is_available() else torch.float32,\n    device_map=\"auto\"\n)","metadata":{"id":"VTVkiXMyBFSD","outputId":"c6498803-3854-4d7f-dfdc-d79d973a8a8f","trusted":true,"execution":{"iopub.status.busy":"2025-07-20T17:53:23.78993Z","iopub.execute_input":"2025-07-20T17:53:23.790117Z","iopub.status.idle":"2025-07-20T17:57:14.150597Z","shell.execute_reply.started":"2025-07-20T17:53:23.790102Z","shell.execute_reply":"2025-07-20T17:57:14.149832Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/47.0k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4e285d8bb8804b8cbce6eb452cf1859c"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.model:   0%|          | 0.00/4.24M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8648097392b54eef9c484fa1670f405f"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/17.5M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"524e77223ad54992add8ae374ed2c90d"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"special_tokens_map.json:   0%|          | 0.00/636 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"563292a2446646109c57b37d15123764"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/857 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9102aa9000fc40f68d0dfb950babc706"}},"metadata":{}},{"name":"stderr","text":"2025-07-20 17:53:36.507102: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\nWARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nE0000 00:00:1753034016.878683      36 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\nE0000 00:00:1753034016.988991      36 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"model.safetensors.index.json:   0%|          | 0.00/39.1k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1ad180744dfa48c486b4a32c48c6bbb8"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Fetching 4 files:   0%|          | 0/4 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"760543e36cc546988b342ff5868b974d"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model-00004-of-00004.safetensors:   0%|          | 0.00/3.67G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c6899cadb9ca4f4b8d872a38e45bcaa5"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model-00002-of-00004.safetensors:   0%|          | 0.00/4.95G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1d68e32c8b1849688d7cf35aa6f255a2"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model-00003-of-00004.safetensors:   0%|          | 0.00/4.96G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"842d6ed9683345e49145c6923fd8bc35"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model-00001-of-00004.safetensors:   0%|          | 0.00/4.90G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"be319ebf68d94aa4b1ca368533d2bde3"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7f3152ac9986472ea21010c5ca44faed"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"generation_config.json:   0%|          | 0.00/173 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"778373fbf6a044929ffbeb1b7aca6d35"}},"metadata":{}}],"execution_count":4},{"cell_type":"code","source":"\ninputs = tokenizer(prompt, return_tensors=\"pt\").to(model.device)\n\nwith torch.no_grad():\n    output_tokens = model.generate(\n        **inputs,\n        max_new_tokens=1024,\n        do_sample=False,\n        temperature=0.2,\n        eos_token_id=tokenizer.eos_token_id,\n)\n\nresponse = tokenizer.decode(output_tokens[0], skip_special_tokens=True)\n","metadata":{"id":"h7NR4necD7SU","outputId":"78d80cde-95e7-4036-848b-69b4eae602e5","trusted":true,"execution":{"iopub.status.busy":"2025-07-20T17:57:14.152235Z","iopub.execute_input":"2025-07-20T17:57:14.152751Z","iopub.status.idle":"2025-07-20T17:59:59.176582Z","shell.execute_reply.started":"2025-07-20T17:57:14.152732Z","shell.execute_reply":"2025-07-20T17:59:59.175995Z"}},"outputs":[{"name":"stderr","text":"The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\nW0720 17:58:12.973000 36 torch/_inductor/utils.py:1137] [0/0] Not enough SMs to use max_autotune_gemm mode\nW0720 17:58:12.984000 36 torch/_inductor/utils.py:1137] [0/0] Not enough SMs to use max_autotune_gemm mode\nskipping cudagraphs due to skipping cudagraphs due to multiple devices: device(type='cuda', index=0), device(type='cuda', index=1)\n","output_type":"stream"}],"execution_count":5},{"cell_type":"code","source":"print(response)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-20T17:59:59.177239Z","iopub.execute_input":"2025-07-20T17:59:59.177469Z","iopub.status.idle":"2025-07-20T17:59:59.181662Z","shell.execute_reply.started":"2025-07-20T17:59:59.177453Z","shell.execute_reply":"2025-07-20T17:59:59.180972Z"}},"outputs":[{"name":"stdout","text":"Below is a text paired with input that provides further context. Write JSON output only json code as output.\n### Input:\n# \"MkDocs Publisher\" Action\n\nI keep repeating the steps to build and deploy our MkDocs documentation sites to GitHub Pages across different repos. Let's create a reusable composite action to handle this.\n\nAction Name: MkDocs Publisher\nPurpose: A simple action to build an MkDocs site and push it to the gh-pages branch. Should be easy to use. Author should be listed as 'DevRel Team'.\n\nInputs Needed:\n\npython-version: We need to specify the Python version for setting up the environment. Users should be able to choose. Let's make this optional and default it to 3.11. Description: 'The version of Python to set up for building.'\nrequirements-file: Users might have different requirements files (e.g., requirements.txt, docs/requirements.txt). This input should specify the path. It's required. Description: 'Path to the Python requirements file'.\ngh-token: The GitHub token for pushing to gh-pages. This is absolutely required. Description: 'GitHub token for deployment.' Let's add a note that this is usually ${{ secrets.GITHUB_TOKEN }}. We should probably add a deprecation message to this input later if we find a better way, maybe: \"Prefer using GITHUB_TOKEN environment variable directly if permissions allow.\"\nOutputs:\n\nThe action needs to output the URL where the site was deployed. Let's call this output page-url. Its description should be 'The URL of the deployed GitHub Pages site.' The actual value should come from the deployment step (see below).\n\nHow it Runs (Execution):\n\nThis will be a composite action (using: composite). Here are the steps involved:\n\nCheckout Code: First, we need the repository code. Use the standard actions/checkout@v4.\nSetup Python: Next, set up the Python environment. Use actions/setup-python@v5. We must use the python-version input provided by the user here. Let's ID this step as setup_python.\nInstall Dependencies: Run a command to install the Python packages. The command is pip install -r ${{ inputs.requirements-file }}. Execute this using the bash shell. Maybe give this step the name \"Install Python Packages\".\nBuild Site: Run the command mkdocs build. Use bash for this too.\nDeploy to Pages: Use an existing action for the deployment. peaceiris/actions-gh-pages@v3 seems popular. Give this step the ID deploy. We need to configure it:\nSet its github_token parameter to the gh-token input we defined earlier.\nSet its publish_dir parameter to ./site (which is the default build output dir for MkDocs).\nMaybe add a condition (if:): github.ref == 'refs/heads/main' so it only deploys from the main branch.\n\nRemember the page-url output? Its value needs to be linked to the output of the deploy step. So, for the page-url output, the value should be ${{ steps.deploy.outputs.page_url }}.\n\nBranding:\nFor the marketplace look, let's use the color blue and the book-open icon. Looks professional.\n\n### Schema:\n{\n  \"$schema\": \"http://json-schema.org/draft-07/schema#\",\n  \"type\": \"object\",\n  \"properties\": {\n    \"action_name\": {\n      \"type\": \"string\"\n    },\n    \"purpose\": {\n      \"type\": \"string\"\n    },\n    \"author\": {\n      \"type\": \"string\"\n    },\n    \"inputs\": {\n      \"type\": \"object\",\n      \"additionalProperties\": {\n        \"type\": \"object\",\n        \"properties\": {\n          \"required\": {\n            \"type\": \"boolean\"\n          },\n          \"default\": {\n            \"type\": [\n              \"string\",\n              \"null\"\n            ]\n          },\n          \"description\": {\n            \"type\": \"string\"\n          }\n        },\n        \"required\": [\n          \"required\",\n          \"description\"\n        ]\n      }\n    },\n    \"outputs\": {\n      \"type\": \"object\",\n      \"additionalProperties\": {\n        \"type\": \"object\",\n        \"properties\": {\n          \"description\": {\n            \"type\": \"string\"\n          },\n          \"value_from\": {\n            \"type\": \"string\"\n          }\n        },\n        \"required\": [\n          \"description\",\n          \"value_from\"\n        ]\n      }\n    },\n    \"runs\": {\n      \"type\": \"object\",\n      \"properties\": {\n        \"using\": {\n          \"type\": \"string\"\n        },\n        \"steps\": {\n          \"type\": \"array\",\n          \"items\": {\n            \"type\": \"object\"\n          }\n        }\n      },\n      \"required\": [\n        \"using\",\n        \"steps\"\n      ]\n    },\n    \"branding\": {\n      \"type\": \"object\",\n      \"properties\": {\n        \"color\": {\n          \"type\": \"string\"\n        },\n        \"icon\": {\n          \"type\": \"string\"\n        }\n      },\n      \"required\": [\n        \"color\",\n        \"icon\"\n      ]\n    }\n  },\n  \"required\": [\n    \"action_name\",\n    \"purpose\",\n    \"author\",\n    \"inputs\",\n    \"outputs\",\n    \"runs\",\n    \"branding\"\n  ]\n}\n### Response:\n```json\n{\n  \"action_name\": \"MkDocs Publisher\",\n  \"purpose\": \"A simple action to build an MkDocs site and push it to the gh-pages branch. Should be easy to use.\",\n  \"author\": \"DevRel Team\",\n  \"inputs\": {\n    \"python-version\": {\n      \"required\": false,\n      \"default\": \"3.11\",\n      \"description\": \"The version of Python to set up for building.\"\n    },\n    \"requirements-file\": {\n      \"required\": true,\n      \"default\": null,\n      \"description\": \"Path to the Python requirements file\"\n    },\n    \"gh-token\": {\n      \"required\": true,\n      \"default\": null,\n      \"description\": \"GitHub token for deployment. Usually ${{ secrets.GITHUB_TOKEN }}. Prefer using GITHUB_TOKEN environment variable directly if permissions allow.\"\n    }\n  },\n  \"outputs\": {\n    \"page-url\": {\n      \"description\": \"The URL of the deployed GitHub Pages site.\",\n      \"value_from\": \"${{ steps.deploy.outputs.page_url }}\"\n    }\n  },\n  \"runs\": {\n    \"using\": \"composite\",\n    \"steps\": [\n      {\n        \"name\": \"Checkout Code\",\n        \"id\": \"checkout\",\n        \"uses\": \"actions/checkout@v4\"\n      },\n      {\n        \"name\": \"Setup Python\",\n        \"id\": \"setup_python\",\n        \"uses\": \"actions/setup-python@v5\",\n        \"with\": {\n          \"python-version\": \"${{ inputs.python-version }}\"\n        }\n      },\n      {\n        \"name\": \"Install Python Packages\",\n        \"run\": \"pip install -r ${{ inputs.requirements-file }}\",\n        \"shell\": \"bash\"\n      },\n      {\n        \"name\": \"Build Site\",\n        \"run\": \"mkdocs build\",\n        \"shell\": \"bash\"\n      },\n      {\n        \"name\": \"Deploy to Pages\",\n        \"id\": \"deploy\",\n        \"uses\": \"peaceiris/actions-gh-pages@v3\",\n        \"with\": {\n          \"github_token\": \"${{ inputs.gh-token }}\",\n          \"publish_dir\": \"./site\",\n          \"if\": \"github.ref == 'refs/heads/main'\"\n        }\n      }\n    ]\n  },\n  \"branding\": {\n    \"color\": \"blue\",\n    \"icon\": \"book-open\"\n  }\n}\n```\n","output_type":"stream"}],"execution_count":6},{"cell_type":"code","source":"!pip install -q gradio","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-20T17:59:59.182317Z","iopub.execute_input":"2025-07-20T17:59:59.182679Z","iopub.status.idle":"2025-07-20T18:00:06.928624Z","shell.execute_reply.started":"2025-07-20T17:59:59.182651Z","shell.execute_reply":"2025-07-20T18:00:06.927597Z"}},"outputs":[],"execution_count":7},{"cell_type":"code","source":"\nimport gradio as gr\n\n\n# Assuming schema.json exists and contains the schema you want to use\ntry:\n    with open(\"schema.json\", \"r\") as f:\n        json_schema = json.load(f)\nexcept FileNotFoundError:\n    # Create a dummy schema.json if it doesn't exist for demonstration\n    print(\"Schema file not found. Creating a dummy schema.\")\n\n\njson_schema_str = json.dumps(json_schema, indent=2)\n\n\ndef generate_json_from_text(input_text):\n    prompt = f'''Below is a text paired with input that provides further context. Write JSON output only json outpu.\n### Input:\n{input_text}\n### Schema:\n{json_schema_str}\n### Response:\n'''\n    inputs = tokenizer(prompt, return_tensors=\"pt\").to(model.device)\n    with torch.no_grad():\n        output_tokens = model.generate(\n            **inputs,\n            max_new_tokens=1024,\n            do_sample=False,\n            temperature=0.2,\n            eos_token_id=tokenizer.eos_token_id,\n        )\n    response = tokenizer.decode(output_tokens[0], skip_special_tokens=True)\n    # Extract only the JSON part from the response if the model includes extra text\n    try:\n        response_after_marker = response.split(\"### Response:\")[-1].strip()\n        first_brace = response_after_marker.find('{')\n        last_brace = response_after_marker.rfind('}')\n        json_str = response_after_marker[first_brace:last_brace + 1]\n        json_obj = json.loads(json_str)\n        return json.dumps(json_obj, indent=2)\n    except json.JSONDecodeError:\n        return \"Could not parse JSON from model output:\\n\" + response\n\n\niface = gr.Interface(\n    fn=generate_json_from_text,\n    inputs=gr.Textbox(lines=20, placeholder=\"Enter your text here...\", label=\"Input Text\"),\n    outputs=gr.Textbox(lines=20, label=\"Generated JSON Output\"),\n    title=\"Text to JSON with Gemma\",\n    description=\"Enter text and the model will attempt to generate JSON based on a provided schema.\"\n)\n\niface.launch(share=True)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-20T18:04:20.972076Z","iopub.execute_input":"2025-07-20T18:04:20.972765Z","iopub.status.idle":"2025-07-20T18:04:21.980643Z","shell.execute_reply.started":"2025-07-20T18:04:20.972739Z","shell.execute_reply":"2025-07-20T18:04:21.980062Z"}},"outputs":[{"name":"stdout","text":"Schema file not found. Creating a dummy schema.\n* Running on local URL:  http://127.0.0.1:7861\n* Running on public URL: https://7bf2f008bd20140829.gradio.live\n\nThis share link expires in 1 week. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"<div><iframe src=\"https://7bf2f008bd20140829.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"},"metadata":{}},{"execution_count":10,"output_type":"execute_result","data":{"text/plain":""},"metadata":{}},{"name":"stderr","text":"The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n","output_type":"stream"}],"execution_count":10}]}